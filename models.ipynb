{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72c4bae-0aba-4c13-ad51-e4b3a318f614",
   "metadata": {},
   "source": [
    "# This notebook contains various predictive modeling techniques to forecast bakery daily sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f09e763-95bd-4341-8a62-661820ba7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA  # Updated import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc171d07-c08a-4a1a-a80b-aea8eb28f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3396c8-78d8-4be1-9f3e-7c340c894864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model\n",
    "class ArimaModel:\n",
    "    def __init__(self, train_data, test_data, order=(5, 1, 5)):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.order = order\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.pred = None\n",
    "\n",
    "    def fit(self):\n",
    "        # Scale the data\n",
    "        self.train_scaled = self.scaler.fit_transform(self.train_data[['daily_sales']])\n",
    "        self.test_scaled = self.scaler.transform(self.test_data[['daily_sales']])\n",
    "        \n",
    "        # Fit the ARIMA model on the scaled training data\n",
    "        self.model = ARIMA(self.train_scaled, order=self.order)\n",
    "        self.model = self.model.fit()\n",
    "\n",
    "    def predict(self):\n",
    "        # Predict on the scaled test data\n",
    "        start = len(self.train_scaled) \n",
    "        end = len(self.train_scaled) + len(self.test_scaled) - 1\n",
    "        pred_scaled = self.model.predict(start=start, end=end, typ='levels')\n",
    "\n",
    "        # Inverse transform the predictions to get them back to the original scale\n",
    "        self.pred = self.scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
    "        return self.pred\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        # Plot the predictions\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.pred, label='ARIMA Predictions')\n",
    "        plt.plot(self.test_data['daily_sales'].values, label='Actual Sales')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Calculate RMSE\n",
    "        rmse = sqrt(mean_squared_error(self.pred, self.test_data['daily_sales'].values))\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ffbda2-6657-4999-acef-d2e0c889d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model with external data\n",
    "class ArimaModelWithExternal:\n",
    "    def __init__(self, train_data, test_data, exog_train, exog_test, order=(5, 1, 5)):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.exog_train = exog_train\n",
    "        self.exog_test = exog_test\n",
    "        self.order = order\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.pred = None\n",
    "\n",
    "    def fit(self):\n",
    "        # Scale the data\n",
    "        self.train_scaled = self.scaler.fit_transform(self.train_data[['daily_sales']])\n",
    "        self.test_scaled = self.scaler.transform(self.test_data[['daily_sales']])\n",
    "        \n",
    "        # Convert exogenous variables to numeric if necessary\n",
    "        self.exog_train = pd.to_numeric(self.exog_train)\n",
    "        self.exog_test = pd.to_numeric(self.exog_test)\n",
    "        \n",
    "        # Fit the ARIMA model with external regressors on the scaled training data\n",
    "        self.model = ARIMA(self.train_scaled, order=self.order, exog=self.exog_train)\n",
    "        self.model = self.model.fit()\n",
    "        \n",
    "    def predict(self):\n",
    "        # Predict on the scaled test data with external regressors\n",
    "        start = len(self.train_scaled)\n",
    "        end = len(self.train_scaled) + len(self.test_scaled) - 1\n",
    "        pred_scaled = self.model.predict(start=start, end=end, exog=self.exog_test)\n",
    "\n",
    "        # Inverse transform the predictions to get them back to the original scale\n",
    "        # Added np.array(pred_scaled) before reshaping\n",
    "        self.pred = self.scaler.inverse_transform(np.array(pred_scaled).reshape(-1, 1)).flatten()\n",
    "        return self.pred\n",
    "\n",
    "    def plot_predictions(self):\n",
    "        # Plot the predictions\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.pred, label='ARIMA Predictions')\n",
    "        plt.plot(self.test_data['daily_sales'].values, label='Actual Sales')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Calculate RMSE\n",
    "        rmse = sqrt(mean_squared_error(self.pred, self.test_data['daily_sales'].values))\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf4d470-9890-4cbb-96c0-9262d9a5327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model without external data\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521d43a9-e147-40af-a482-ca5c4333ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with external data\n",
    "class LSTMModelWithExternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(LSTMModelWithExternal, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim + 1, 1)\n",
    "    \n",
    "    def forward(self, sales_seq, holiday_seq):\n",
    "        lstm_out, _ = self.lstm(sales_seq)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        combined = torch.cat((lstm_out, holiday_seq[:, -1].unsqueeze(1)), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7ca82e-2c36-4594-a128-dd2b6fdc9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM Model without external data\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cnn = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(64, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b5e6b0-fe3b-4af5-bfac-bb53f06f2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM Model with external data\n",
    "class CNNLSTMModelWithExternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(CNNLSTMModelWithExternal, self).__init__()\n",
    "        self.cnn = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(64, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim + 1, 1)\n",
    "\n",
    "    def forward(self, sales_seq, holiday_seq):\n",
    "        sales_seq = sales_seq.permute(0, 2, 1)  # Reshape for CNN\n",
    "        cnn_out = self.cnn(sales_seq)\n",
    "        cnn_out = cnn_out.permute(0, 2, 1)  # Reshape back for LSTM\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        combined = torch.cat((lstm_out, holiday_seq[:, -1].unsqueeze(1)), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b538f3af-7b90-4e4d-92ee-ecef48349007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model without external data\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "047b0a9f-3d8c-41e0-b169-6b96a817d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model with external data\n",
    "class GRUModelWithExternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(GRUModelWithExternal, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim + 1, 1)\n",
    "\n",
    "    def forward(self, sales_seq, holiday_seq):\n",
    "        gru_out, _ = self.gru(sales_seq)\n",
    "        gru_out = gru_out[:, -1, :]\n",
    "        combined = torch.cat((gru_out, holiday_seq[:, -1].unsqueeze(1)), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c2a00b-9aa9-40ae-8cc4-c008905338d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model without external data\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, nhead=4):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.positional_encoding = self.generate_positional_encoding(hidden_size, 5000)\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def generate_positional_encoding(self, hidden_size, max_len):\n",
    "        positional_encoding = torch.zeros(max_len, hidden_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-np.log(10000.0) / hidden_size))\n",
    "        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        return positional_encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "        x = x.permute(1, 0, 2)\n",
    "        out = self.transformer_encoder(x)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe835330-f8da-45a9-8d07-d8447e867551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e1608-08b8-43c4-86eb-51a776a08c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
